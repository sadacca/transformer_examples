{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyMf2LdJtGdtf1kS9JTXHyi+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9d43e330ff684519b3524df0e4499af8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb23e5757e7b48679c9b5957b03735af","IPY_MODEL_9aa41efac1ec45aab5bfc4f02a6e89c8","IPY_MODEL_96b7dfdc41d54745ad0d0fc221f477b3"],"layout":"IPY_MODEL_4e7d8dbd5d9e4bdc87258e3d03b764db"}},"fb23e5757e7b48679c9b5957b03735af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_507018e7b73c4a48bce55af02c75c219","placeholder":"​","style":"IPY_MODEL_325cf946e35c4978ada82671031897b2","value":"Map: 100%"}},"9aa41efac1ec45aab5bfc4f02a6e89c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e363fd3357e048b1ba3a712bc499d207","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_671044b1b6774857b142372fa925aba1","value":200}},"96b7dfdc41d54745ad0d0fc221f477b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7422e1f84e545cc8cf40014277251a6","placeholder":"​","style":"IPY_MODEL_5910411203c041a582eb88d8f14feda4","value":" 200/200 [00:00&lt;00:00, 721.33 examples/s]"}},"4e7d8dbd5d9e4bdc87258e3d03b764db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507018e7b73c4a48bce55af02c75c219":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"325cf946e35c4978ada82671031897b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e363fd3357e048b1ba3a712bc499d207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"671044b1b6774857b142372fa925aba1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7422e1f84e545cc8cf40014277251a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5910411203c041a582eb88d8f14feda4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Notebook to review using language models in a classifier with non-text data\n","This notebook loads relevent libaries, a review dataset (amazon reviews) and demonstrates on how to combine text, categorical data, and numeric data with a transformer model in two ways:  \n","- Path 1 (XGBOOST): using a transformer model to interpret the text data, as an input to an xgboost classifier with other supporting numeric or categorical information\n","- Path 2 (BERT): supplimenting the text input with categorical or numeric information at the time of classification within the transformer model itself"],"metadata":{"id":"O1rxw2vvj-rE"}},{"cell_type":"code","source":["%%capture\n","## capture with jupyter magic to suppress output\n","\n","## install needed libraries\n","!pip install xgboost datasets transformers sentence_transformers nltk accelerate evaluate"],"metadata":{"id":"TnEbXn0Fkk37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","\n","from transformers import pipeline\n","from datasets import load_dataset,ReadInstruction\n","\n","## first we'll load some assets to process the data\n","sentiment_pipe = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n","\n","## then we'll load a small subset of a review dataset (200 reviews)\n","dataset = load_dataset(\"amazon_polarity\", split = ReadInstruction('test', to=0.05, unit='%'))"],"metadata":{"id":"9kMi2e6bkDYI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Path 1 (XGBOOST):\n","### numerical/categorical and transformer output into XGBOOST"],"metadata":{"id":"sTL57ufPnhf-"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# for intput into an xgboost classifier, first convert to a pandas dataframe\n","df_revs = pd.DataFrame(dataset)\n","\n","## as a toy example, let's calculate some basic numeric and categorical data about reviews\n","\n","# numeric: how many characters are in there review? (more is better?)\n","df_revs['content_len']=df_revs.content.str.len()\n","\n","# categorical: does the review have an exclamation point? (excitement can be good! or bad!)\n","df_revs['has_exclamation_cat'] = df_revs.content.str.contains('!').astype('category')"],"metadata":{"id":"hemOJwJ5n9Yk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# once the toy date are prepared, let's split our data into training and eval subsets\n","train, test = train_test_split(df_revs, test_size=0.2)\n","dtrain = xgb.DMatrix(train[['content_len','has_exclamation_cat']], label=train['label'],enable_categorical=True)\n","dtest = xgb.DMatrix(test[['content_len','has_exclamation_cat']], label=test['label'],enable_categorical=True)\n","\n","#set a few xgboost params\n","param = {'max_depth': 2,'eta':0.3}\n","\n","# and train our toy model\n","model = xgb.train(param, dtrain, 10)\n","\n","# in evaluation this toy model typically does poorly (accuracy between 45-65%)\n","y_pred = model.predict(dtest)\n","predictions = [round(value) for value in y_pred]\n","accuracy = accuracy_score(test['label'], predictions)\n","print(\"Accuracy: \")\n","print(\" %.2f%%\" % (accuracy * 100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_u0qp9Qqrw7","executionInfo":{"status":"ok","timestamp":1691583898230,"user_tz":240,"elapsed":339,"user":{"displayName":"Brian Sadacca","userId":"03876506140942283538"}},"outputId":"ce9277f7-f7d7-42dd-a946-d77b95b204e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: \n"," 65.00%\n"]}]},{"cell_type":"code","source":["## to improve, let's add additional variables as calculated from text data\n","# below we use a transformer-based sentiment analysis model, trained on reviews\n","# (output: the numeric variable bert_score and the categorical variable bert_stars)\n","# however converting text to numeric data can also include vector representations of each review (e.g. from bert / mpnet / word2vec embeddings, tf-idf vectors)\n","# or could be through categorization of the data otherwise (e.g. topic id as a categorical variable from a topic model)\n","\n","# calculate bert-based sentiment scores\n","# takes about 2.5min to process 200 records on a standard colab notebook\n","x=sentiment_pipe(dataset['content'],batch_size=8)\n","\n","### then - use the transformer-based sentiment output to update our traning and evaluation data\n","df_revs['bert_stars']=pd.Series([reviews['label'] for reviews in x]).astype('category')\n","df_revs['bert_score']=pd.Series([reviews['score'] for reviews in x]).astype('float')"],"metadata":{"id":"8PgVu9mBW-Pb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## finally - retrain a model with our initial variables and sentiment\n","# include the vader polarity in the training data\n","train, test = train_test_split(df_revs, test_size=0.2)\n","dtrain = xgb.DMatrix(train[['content_len','has_exclamation_cat','bert_score','bert_stars']], label=train['label'],enable_categorical=True)\n","dtest = xgb.DMatrix(test[['content_len','has_exclamation_cat','bert_score','bert_stars']], label=test['label'],enable_categorical=True)\n","\n","# train a new model\n","model = xgb.train(param, dtrain, 10)\n","\n","# evaluate the output, in terms of accuracy of predicting the input labels\n","y_pred = model.predict(dtest)\n","predictions = [round(value) for value in y_pred]\n","accuracy = accuracy_score(test['label'], predictions)\n","print(\"Accuracy: \")\n","print(\"  %.2f%%\" % (accuracy * 100.0)) #averages between 85-90% in runs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kItWjBpd45fy","executionInfo":{"status":"ok","timestamp":1691584053248,"user_tz":240,"elapsed":26,"user":{"displayName":"Brian Sadacca","userId":"03876506140942283538"}},"outputId":"8d408329-9121-4e27-dc99-f0f1c6233cb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: \n","  87.50%\n"]}]},{"cell_type":"markdown","source":["## Path 2 (BERT):\n","### everything (pre-trained transformer's embedding + numerical/categorical data) as an input into last layer of a transformer-based classifier"],"metadata":{"id":"VXwEFQ9onz6E"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from transformers import AutoConfig, BertModel, BertForSequenceClassification\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","from typing import Optional, Union, Tuple\n","\n","### Create a custom model that predicts labels based on a final hidden state which\n","### combines the initial model's embedding plus additional numeric/categorical data\n","\n","# A custom classification head (last layer)\n","# is required to match the dimensionality\n","# of the final representation\n","# combining both text embedding and additional data\n","# and defined as input num_extra_dims\n","\n","class ClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    def __init__(self, config, num_extra_dims):\n","        super().__init__()\n","        total_dims = config.hidden_size+num_extra_dims\n","        self.dense = nn.Linear(total_dims, total_dims)\n","        classifier_dropout = (\n","            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n","        )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.out_proj = nn.Linear(total_dims, config.num_labels)\n","\n","    def forward(self, features, **kwargs):\n","        x = self.dropout(features)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.out_proj(x)\n","        return x\n","\n","# A custom model configuration class applying\n","# the custom classification head (with a size to accept our expanded input)\n","# which can be user specified through the input num_extra_dims\n","\n","class CustomSequenceClassification(BertForSequenceClassification):\n","\n","    def __init__(self, config, num_extra_dims):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","        self.config = config\n","\n","        # This needs ot be renamed based on base model used\n","        # e.g. BertModel, RobertaModel, etc\n","        self.bert =  BertModel(config)\n","\n","        # and the classifier set to use the ClassificationHead as specified above\n","        self.classifier = ClassificationHead(config, num_extra_dims)\n","        self.post_init()\n","\n","    # note addition of extra_data\n","    def forward(\n","        self,\n","        input_ids: Optional[torch.LongTensor] = None,\n","        attention_mask: Optional[torch.FloatTensor] = None,\n","        extra_data: Optional[torch.FloatTensor] = None,\n","        token_type_ids: Optional[torch.LongTensor] = None,\n","        position_ids: Optional[torch.LongTensor] = None,\n","        head_mask: Optional[torch.FloatTensor] = None,\n","        inputs_embeds: Optional[torch.FloatTensor] = None,\n","        labels: Optional[torch.LongTensor] = None,\n","        output_attentions: Optional[bool] = None,\n","        output_hidden_states: Optional[bool] = None,\n","        return_dict: Optional[bool] = None,\n","    ) -> Union[Tuple, SequenceClassifierOutput]:\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n","            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n","            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n","            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n","        \"\"\"\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        # sequence_output will be (batch_size, seq_length, hidden_size)\n","        sequence_output = outputs[0]\n","\n","        # additional data should be (batch_size, num_extra_dims)\n","        cls_embedding = sequence_output[:, 0, :]\n","\n","        # note the addition of extra_data concatenated to the sentence embedding\n","        output = torch.cat((cls_embedding, extra_data), dim=-1)\n","\n","        logits = self.classifier(output)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.config.problem_type is None:\n","                if self.num_labels == 1:\n","                    self.config.problem_type = \"regression\"\n","                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n","                    self.config.problem_type = \"single_label_classification\"\n","                else:\n","                    self.config.problem_type = \"multi_label_classification\"\n","\n","            if self.config.problem_type == \"regression\":\n","                loss_fct = nn.MSELoss()\n","                if self.num_labels == 1:\n","                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n","                else:\n","                    loss = loss_fct(logits, labels)\n","            elif self.config.problem_type == \"single_label_classification\":\n","                loss_fct = nn.CrossEntropyLoss()\n","                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            elif self.config.problem_type == \"multi_label_classification\":\n","                loss_fct = nn.BCEWithLogitsLoss()\n","                loss = loss_fct(logits, labels)\n","\n","        if not return_dict:\n","            output = (logits,) + outputs[2:]\n","            return ((loss,) + output) if loss is not None else output\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"metadata":{"id":"qljp7tqbn-sL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","## import model details from pretrained model used above, including tokenizer\n","## and use of our custom classifier specified in the above cell\n","tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n","new_model = CustomSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\", num_labels=2, num_extra_dims=2)"],"metadata":{"id":"4GC3TcYosj1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from datasets import Dataset\n","\n","# let's make a customized dataset based on the inputs to xgboost\n","\n","\n","# first standardize numeric variables\n","# and one-hot-encode categorical\n","# and bring together in np.array\n","\n","extra_numeric = (df_revs.content_len.values-np.mean(df_revs.content_len.values)\n","                )/np.std(df_revs.content_len.values)\n","\n","extra_cat = df_revs.has_exclamation_cat.astype(int).values\n","\n","extra_data = np.stack((extra_numeric,\n","                       extra_cat)).T\n","\n","# load this dataset (text, plus 'extra data') from a dict and tokenize with our bert model\n","ds = Dataset.from_dict({\"text\": df_revs.content, \"extra_data\": extra_data, \"labels\": df_revs.label})\n","tokenized_ds = ds.map(lambda x: tokenizer(x[\"text\"]))\n","\n","#split out this data for validation based on our earlier 80/20 split\n","ds_train_test = tokenized_ds.train_test_split(test_size = 0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["9d43e330ff684519b3524df0e4499af8","fb23e5757e7b48679c9b5957b03735af","9aa41efac1ec45aab5bfc4f02a6e89c8","96b7dfdc41d54745ad0d0fc221f477b3","4e7d8dbd5d9e4bdc87258e3d03b764db","507018e7b73c4a48bce55af02c75c219","325cf946e35c4978ada82671031897b2","e363fd3357e048b1ba3a712bc499d207","671044b1b6774857b142372fa925aba1","a7422e1f84e545cc8cf40014277251a6","5910411203c041a582eb88d8f14feda4"]},"id":"PJwycd2VtVMT","executionInfo":{"status":"ok","timestamp":1691585941810,"user_tz":240,"elapsed":472,"user":{"displayName":"Brian Sadacca","userId":"03876506140942283538"}},"outputId":"6fd10ccf-8a18-4679-d097-0333ce40cc2a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d43e330ff684519b3524df0e4499af8"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","import evaluate\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","# specify arguments for the trainer (where the model output is to be stored)\n","# and parameters of the trainer, including evaluation data from the train/test split\n","args = TrainingArguments(output_dir=\"./\",eval_delay=0,evaluation_strategy=\"epoch\")\n","trainer = Trainer(model=new_model,\n","                  train_dataset=ds_train_test['train'],\n","                  eval_dataset=ds_train_test['test'],\n","                  tokenizer=tokenizer,\n","                  compute_metrics=compute_metrics,\n","                  args=args)"],"metadata":{"id":"kfDXL3eVtf2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# execute the trainer\n","# note with CPU alone this takes about 20m\n","trainer.train()\n","\n","# perhaps unsuprizingly - this tends to produce similar (but better!) accuracies\n","# as compared to xgboost with numeric, categorical, and model output\n","# (this is averaging between 90-100% accuracy while xgb is ~85-95%)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"yMtlaDVWt0Qu","executionInfo":{"status":"ok","timestamp":1691586342450,"user_tz":240,"elapsed":7559,"user":{"displayName":"Brian Sadacca","userId":"03876506140942283538"}},"outputId":"54bb8889-e2a2-4d3f-b047-b3d40c7812f5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 00:07, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.000073</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.270622</td>\n","      <td>0.975000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.282162</td>\n","      <td>0.975000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=60, training_loss=9.801937267184258e-05, metrics={'train_runtime': 7.4584, 'train_samples_per_second': 64.357, 'train_steps_per_second': 8.045, 'total_flos': 47249469641088.0, 'train_loss': 9.801937267184258e-05, 'epoch': 3.0})"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":[],"metadata":{"id":"uIOIDvuYUhH2"},"execution_count":null,"outputs":[]}]}